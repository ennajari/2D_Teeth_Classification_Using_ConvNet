# Redimensionnement des images.


from PIL import Image
import os
import matplotlib.pyplot as plt

images_dir = 'C:\\Users\\HP\\OneDrive\\Bureau\\S4\\pfa\\dataset_teeth_1\\images'
resized_images_dir = 'C:\\Users\\HP\\OneDrive\\Bureau\\S4\\pfa\\dataset_teeth_1\\resized_images'
os.makedirs(resized_images_dir, exist_ok=True)

for image_file in os.listdir(images_dir):
    img = Image.open(os.path.join(images_dir, image_file))
    img_resized = img.resize((256, 256))  # Resize to 256x256 pixels
    img_resized.save(os.path.join(resized_images_dir, image_file))
    plt.imshow(img_resized)
    plt.title(f'Resized: {image_file}')
    plt.show()

# Normalisation des images, Augmentation de données (si nécessaire).


if img_normalized.ndim == 2:  
    img_normalized = img_normalized[..., np.newaxis]

img_normalized_expanded = np.expand_dims(img_normalized, axis=0)

it = datagen.flow(img_normalized_expanded, batch_size=1)

plt.figure(figsize=(10, 6))
for i in range(6):
    batch = next(it)  
    aug_image = batch[0]
    plt.subplot(2, 3, i + 1)
    plt.imshow(aug_image.squeeze(), cmap='gray')  
    plt.axis('off')
    plt.title('Augmented Image' if i > 0 else 'Original Image')
plt.show()

# Division des données en ensembles d'entraînement, de validation et de test.

from sklearn.model_selection import train_test_split
import os
import numpy as np

images_dir = 'C:\\Users\\HP\\OneDrive\\Bureau\\S4\\pfa\\dataset_teeth_1\\images'  
image_paths = [os.path.join(images_dir, img) for img in os.listdir(images_dir)]
labels = np.random.randint(0, 2, size=len(image_paths))  

X_train, X_temp, y_train, y_temp = train_test_split(image_paths, labels, test_size=0.2, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)

print(f'Training set size: {len(X_train)} images')
print(f'Validation set size: {len(X_val)} images')
print(f'Test set size: {len(X_test)} images')
